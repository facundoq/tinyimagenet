{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (0.15.2)\n",
      "Requirement already satisfied: requests in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: torch==2.0.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: numpy in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torchvision) (1.25.1)\n",
      "Requirement already satisfied: filelock in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: typing-extensions in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (4.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.99)\n",
      "Requirement already satisfied: networkx in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (2.14.3)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (11.7.4.91)\n",
      "Requirement already satisfied: jinja2 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
      "Requirement already satisfied: sympy in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch==2.0.1->torchvision) (1.12)\n",
      "Requirement already satisfied: wheel in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->torchvision) (67.4.0)\n",
      "Requirement already satisfied: cmake in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from requests->torchvision) (2.0.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from requests->torchvision) (3.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: seaborn in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (0.13.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.3 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from seaborn) (3.8.1)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from seaborn) (1.25.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from seaborn) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (23.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (4.44.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (10.0.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.3->seaborn) (1.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.3->seaborn) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: poutyne in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (1.17.1)\n",
      "Requirement already satisfied: torchmetrics in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from poutyne) (1.2.0)\n",
      "Requirement already satisfied: torch in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from poutyne) (2.0.1)\n",
      "Requirement already satisfied: numpy in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from poutyne) (1.25.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (11.7.91)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (11.7.4.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (2.0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (4.7.1)\n",
      "Requirement already satisfied: sympy in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (1.12)\n",
      "Requirement already satisfied: networkx in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (3.1)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (10.9.0.58)\n",
      "Requirement already satisfied: filelock in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (3.12.2)\n",
      "Requirement already satisfied: jinja2 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torch->poutyne) (11.7.99)\n",
      "Requirement already satisfied: wheel in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->poutyne) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->poutyne) (67.4.0)\n",
      "Requirement already satisfied: lit in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from triton==2.0.0->torch->poutyne) (16.0.6)\n",
      "Requirement already satisfied: cmake in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from triton==2.0.0->torch->poutyne) (3.26.4)\n",
      "Requirement already satisfied: lightning-utilities>=0.8.0 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from torchmetrics->poutyne) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.1 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from lightning-utilities>=0.8.0->torchmetrics->poutyne) (23.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from jinja2->torch->poutyne) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages (from sympy->torch->poutyne) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from tinyimagenet import TinyImageNet\n",
    "from pathlib import Path\n",
    "import logging\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "!pip install torchvision\n",
    "!pip install seaborn\n",
    "!pip install poutyne\n",
    "\n",
    "import torch\n",
    "import seaborn as sn\n",
    "import torchvision.models as models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_v2_s-dd5fe13b.pth\" to /home/facundoq/.cache/torch/hub/checkpoints/efficientnet_v2_s-dd5fe13b.pth\n",
      "100%|██████████| 82.7M/82.7M [00:10<00:00, 8.41MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import efficientnet_v2_s,EfficientNet_V2_S_Weights\n",
    "\n",
    "\n",
    "weights = EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
    "base_model = efficientnet_v2_s(weights=weights)\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    weights.transforms(),\n",
    "    base_model\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset TinyImageNet\n",
      "    Number of datapoints: 10000\n",
      "    Root location: /home/facundoq/.torchvision/tinyimagenet/tiny-imagenet-200/val\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Target transform: <function TinyImageNet.__init__.<locals>.<lambda> at 0x7f29cf6dfeb0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/facundoq/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:   3/313   0.96% |▏                   |ETA: 32m6.12s test_loss: 2.170904 test_acc: 50.000000 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/facundoq/dev/tinyimagenet/Eval EfficientNet with TinyImageNet.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m dataloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mprint\u001b[39m(dataset)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39meval\u001b[39;49m(model,dataloader,torch\u001b[39m.\u001b[39;49mdevice(\u001b[39m\"\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "\u001b[1;32m/home/facundoq/dev/tinyimagenet/Eval EfficientNet with TinyImageNet.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval\u001b[39m(model,dataloader,device):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     poutyne_model \u001b[39m=\u001b[39m Model(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         device\u001b[39m=\u001b[39mdevice\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/facundoq/dev/tinyimagenet/Eval%20EfficientNet%20with%20TinyImageNet.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     poutyne_model\u001b[39m.\u001b[39;49mevaluate_generator(dataloader)\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/poutyne/framework/model.py:1378\u001b[0m, in \u001b[0;36mModel.evaluate_generator\u001b[0;34m(self, generator, steps, return_pred, return_ground_truth, return_dict_format, concatenate_returns, convert_to_numpy, verbose, progress_options, callbacks)\u001b[0m\n\u001b[1;32m   1373\u001b[0m step_iterator \u001b[39m=\u001b[39m StepIterator(\n\u001b[1;32m   1374\u001b[0m     generator, steps, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_metrics_names, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepoch_metrics_names, callback_list, mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1375\u001b[0m )\n\u001b[1;32m   1377\u001b[0m test_begin_time \u001b[39m=\u001b[39m timeit\u001b[39m.\u001b[39mdefault_timer()\n\u001b[0;32m-> 1378\u001b[0m pred_y, true_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate(\n\u001b[1;32m   1379\u001b[0m     step_iterator,\n\u001b[1;32m   1380\u001b[0m     return_pred\u001b[39m=\u001b[39;49mreturn_pred,\n\u001b[1;32m   1381\u001b[0m     return_ground_truth\u001b[39m=\u001b[39;49mreturn_ground_truth,\n\u001b[1;32m   1382\u001b[0m     convert_to_numpy\u001b[39m=\u001b[39;49mconvert_to_numpy,\n\u001b[1;32m   1383\u001b[0m )\n\u001b[1;32m   1385\u001b[0m step_iterator\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_loss()\n\u001b[1;32m   1386\u001b[0m step_iterator\u001b[39m.\u001b[39mbatch_metrics \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_batch_metrics()\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/poutyne/framework/model.py:1460\u001b[0m, in \u001b[0;36mModel._validate\u001b[0;34m(self, step_iterator, return_pred, return_ground_truth, convert_to_numpy)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_training_mode(\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   1459\u001b[0m     \u001b[39mfor\u001b[39;00m step, (x, y) \u001b[39min\u001b[39;00m step_iterator:\n\u001b[0;32m-> 1460\u001b[0m         step\u001b[39m.\u001b[39mloss, step\u001b[39m.\u001b[39mbatch_metrics, pred_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_loss_and_metrics(\n\u001b[1;32m   1461\u001b[0m             x, y, return_pred\u001b[39m=\u001b[39;49mreturn_pred, convert_to_numpy\u001b[39m=\u001b[39;49mconvert_to_numpy\n\u001b[1;32m   1462\u001b[0m         )\n\u001b[1;32m   1463\u001b[0m         \u001b[39mif\u001b[39;00m return_pred:\n\u001b[1;32m   1464\u001b[0m             pred_list\u001b[39m.\u001b[39mappend(pred_y)\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/poutyne/framework/model.py:1477\u001b[0m, in \u001b[0;36mModel._compute_loss_and_metrics\u001b[0;34m(self, x, y, return_loss_tensor, return_pred, convert_to_numpy)\u001b[0m\n\u001b[1;32m   1475\u001b[0m     pred_y \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39mdata_parallel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnetwork, x, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mother_device)\n\u001b[1;32m   1476\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1477\u001b[0m     pred_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork(\u001b[39m*\u001b[39;49mx)\n\u001b[1;32m   1478\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss_function(pred_y, y)\n\u001b[1;32m   1479\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_loss_tensor:\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torchvision/models/efficientnet.py:343\u001b[0m, in \u001b[0;36mEfficientNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 343\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torchvision/models/efficientnet.py:333\u001b[0m, in \u001b[0;36mEfficientNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_forward_impl\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 333\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m    335\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m    336\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torchvision/models/efficientnet.py:164\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_res_connect:\n\u001b[1;32m    166\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.virtualenvs/tinyimagenet/lib/python3.10/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from poutyne import Model\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "def eval(model,dataloader,device):\n",
    "\n",
    "    poutyne_model = Model(\n",
    "        model,\n",
    "        'sgd',\n",
    "        'cross_entropy',\n",
    "        batch_metrics=['accuracy'],\n",
    "        epoch_metrics=['f1'],\n",
    "        device=device\n",
    "    )\n",
    "    poutyne_model.evaluate_generator(dataloader)\n",
    "\n",
    "splits = [\"val\",\"train\"]\n",
    "\n",
    "for split in splits:\n",
    "    dataset = TinyImageNet(Path(\"~/.torchvision/tinyimagenet/\"),split=split,imagenet_idx=True,transform=torchvision.transforms.ToTensor())\n",
    "    dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "    print(dataset)\n",
    "    eval(model,dataloader,torch.device(\"cpu\"))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinyimagenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
